{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ANN link : playground.tensorflow.org\n",
    "# Steps in COnvolution Neural Networks\n",
    "1.Convolution\n",
    "2.Max pooling\n",
    "3.Flattening\n",
    "4.Full Connection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step 1:Convolution\n",
    "    *convolution is done to an image using feature dectector\n",
    "    *when input image is convolveed with the feature detector then we get a feature map\n",
    "    *by applying convolution operation size of the image is reduced so we may lose some information. but features detector is one which stores the features and unwanted features are removed.\n",
    "    * WE will apply no of feature detectors(filter) to a single image so we will be getting nof features detectors. SO using no of feature detectors we get max no of features in an image so we will be getting no of feature maps\n",
    "    * Group of feature map is called CONVOLUTION layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step 2:Max pooling\n",
    "Types of pooling-Max pooling,Mean Pooling,Sum pooing\n",
    "Max Pooling:By applyimg max pooling we ar neglecting 75% of unwanted features and we are reducing spacial invariance this will avoid over fitting of the data .\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step3:Flattening\n",
    "flattening is converting n dimension to 1 dimension and applying ann to that 1 dimension array which just acts like inputs to the neurons.\n",
    "When output is not correct then in the backward propogation along with the weights feature detector(filter) is also optimised"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step 4: Full Connection\n",
    "Full connection is dense layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "http://scs.ryerson.ca/~aharley/vis/conv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1:Import Keras Libraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2: Intialize CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: Add Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,3,3,input_shape=(128,128,3),activation='relu'))#1St parameter =no of features detectors 2nd& 3rd =Size of feature detector, \n",
    "#4th input image size,5 th parameter is channel for color=3 gray scale=1,6 th to avoid negative pixels we use activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4:Add Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))#1parmeter=size of pooling matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5: Add flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step6: Ann starts so need to add dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(output_dim=128,activation='relu',init='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(output_dim=1,activation='sigmoid',init='random_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step7:Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step8: Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'D:\\Pradeepthi\\dataset\\dataset\\training_set',target_size=(128,128),batch_size=32,class_mode='binary')\n",
    "x_test = train_datagen.flow_from_directory(r'D:\\Pradeepthi\\dataset\\dataset\\test_set',target_size=(128,128),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(x_train,samples_per_epoch = 8000,epochs=1,validation_data=x_test,nb_val_samples=2000)#(samples_per_epoch= no of traininig or testing images/batch size)\n",
    "                                                                        #                                                       =8000/32=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')# this will save the weights,for keras h5 is extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
